import os
import asyncio
from dotenv import load_dotenv
from aiogram import Bot, Dispatcher, types
from aiogram.filters import CommandStart
from aiogram.types import ReplyKeyboardMarkup, KeyboardButton

# –î–ª—è –º–æ–¥–µ–ª–∏ —Ç–µ–∫—Å—Ç–∞
from gpt4all import GPT4All

# –î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
from diffusers import StableDiffusionPipeline
import torch
from PIL import Image
import io

# ----------------- Load .env -----------------
load_dotenv()
BOT_TOKEN = os.getenv("TOKEN")
ADMIN_USERNAME = os.getenv("ADMIN_USERNAME", "mellfreezy")

bot = Bot(token=BOT_TOKEN)
dp = Dispatcher()

# ----------------- Access -----------------
allowed_users = set([ADMIN_USERNAME])

def is_allowed(username):
    return username in allowed_users

# ----------------- Keyboards -----------------
kb = ReplyKeyboardMarkup(
    keyboard=[[KeyboardButton("üß† Chat"), KeyboardButton("üñºÔ∏è Image")]],
    resize_keyboard=True
)

# ----------------- Initialize models -----------------
print("–ó–∞–≥—Ä—É–∂–∞–µ–º GPT4All (—Ç–µ–∫—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å)...")
chat_model = GPT4All("gpt4all-lora-quantized")  # –º–æ–¥–µ–ª—å —Å–∫–∞—á–∏–≤–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ

print("–ó–∞–≥—Ä—É–∂–∞–µ–º Stable Diffusion (CPU)...")
pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float32
)
pipe = pipe.to("cpu")

# ----------------- Handlers -----------------
@dp.message(CommandStart())
async def start(m: types.Message):
    if not is_allowed(m.from_user.username):
        await m.answer("‚õî –ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞.")
        return
    await m.answer("–ü—Ä–∏–≤–µ—Ç! –í—ã–±–µ—Ä–∏ —Ä–µ–∂–∏–º:", reply_markup=kb)

@dp.message(lambda msg: msg.text == "üß† Chat")
async def chat_mode(m: types.Message):
    if not is_allowed(m.from_user.username):
        await m.answer("‚õî –ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞.")
        return
    await m.answer("–ù–∞–ø–∏—à–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –º–æ–¥–µ–ª–∏:")
    dp.message.register(handle_chat, lambda mm: mm.from_user.username == m.from_user.username)

async def handle_chat(m: types.Message):
    dp.message.unregister(handle_chat)
    prompt = m.text.strip()
    await m.answer("‚åõ –ú–æ–¥–µ–ª—å –¥—É–º–∞–µ—Ç...")
    try:
        response = chat_model.generate(prompt)
        await m.answer(response)
    except Exception as e:
        await m.answer(f"–û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏: {e}")

@dp.message(lambda msg: msg.text == "üñºÔ∏è Image")
async def image_mode(m: types.Message):
    if not is_allowed(m.from_user.username):
        await m.answer("‚õî –ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞.")
        return
    await m.answer("–û—Ç–ø—Ä–∞–≤—å –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:")
    dp.message.register(handle_image, lambda mm: mm.from_user.username == m.from_user.username)

async def handle_image(m: types.Message):
    dp.message.unregister(handle_image)
    prompt = m.text.strip()
    await m.answer("üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
    try:
        image = pipe(prompt, height=512, width=512).images[0]
        bio = io.BytesIO()
        image.save(bio, format="PNG")
        bio.seek(0)
        await m.answer_photo(photo=bio)
    except Exception as e:
        await m.answer(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")

# ----------------- Fallback -----------------
@dp.message()
async def fallback(m: types.Message):
    if is_allowed(m.from_user.username):
        await m.reply("–ò—Å–ø–æ–ª—å–∑—É–π –∫–Ω–æ–ø–∫–∏ üß† Chat –∏–ª–∏ üñºÔ∏è Image (–∏–ª–∏ /start).")

# ----------------- Run -----------------
async def main():
    print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω!")
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
